\section{Methods}
\label{sec:methods}

We would like to solve eq. \ref{eq:poisson} numerically. Generalising the
equation, we get
  \begin{equation} \label{eq:gendiff}
    -\dv[2]{u}{x} = f\qty(x),
  \end{equation}
where we have assumed that $\rho \propto \frac{1}{r}e^{-r}$ and let $ r
\rightarrow x$, $\phi \rightarrow u$.
Summing the backward and forward Taylor expansions of $u(x)$ and discretising
the equation for $n$ integration points, we get:
  \begin{equation}
  \label{eq:approx}
    \frac{v_{i+1} - 2v_i + v_{i-1}}{h^2} + \order{h^2} = f_i,
  \end{equation}
where $h = \frac{1}{n+1}$. Using the Dirichlet boundary conditions
$v_0 = v_{n+1} = 0$ and only considering $x\in\qty(0, 1)$, we can rewrite the
equation as a set of linear equations, represented as the following matrix
equation:
  \begin{equation}
  \label{eq:matrixeq}
    A\vb{v} = \vb{d},
  \end{equation}
where
  \[A =
    \mqty[2 & -1 & 0 & \hdots & \hdots & 0 \\
          -1 & 2 & -1 & 0 & \hdots & 0 \\
          0 & -1 & 2 & -1 & \hdots & 0 \\
          \vdots & \ddots & \ddots & \ddots & \ddots & \vdots \\
          0 & \hdots & \ddots & -1 & 2 & -1 \\
          0 & \hdots & \hdots & 0 & -1 & 2],
  \]
is a tridiagonal matrix and $d_i = h^2f_i$.
Having the equation in this form, we can use linear algebra to solve the set of
linear equations, and obtain the 2nd derivative of $u\qty(x)$.


\subsection{Gaussian elimination}
\label{sec:gaussian}

The fact that $A$ is tridiagonal, means that we can develop a general algorithm
to solve the equations by the method of Gaussian elimination. If we generalise
our matrix
  \[A =
    \mqty[b_1 & c_1 & 0 & \hdots & \hdots & 0 \\
          a_1 & b_2 & c_2 & 0 & \hdots & 0 \\
          0 & a_2 & b_3 & c_3 & \hdots & 0 \\
          \vdots & \ddots & \ddots & \ddots & \ddots & \vdots \\
          0 & \hdots & \ddots & a_{n-2} & b_{n-1} & c_{n-1} \\
          0 & \hdots & \hdots & 0 & a_{n-1} & b_n],
  \]
and row reduce $A$ to become upper-triangular (see appendix A.)
This yields us the following relations:
  \begin{equation}  \label{eq:gaussian}
    \widetilde{b_i} = b_i - \frac{a_{i-1}}{\tilde{b}_{i-1}}c_{i-1}, \quad
    \widetilde{d_i} = d_i - \frac{a_{i-1}}{\tilde{b}_{i-1}}\tilde{d}_{i-1},
  \end{equation}
where $\widetilde{b_1} \equiv b_1$ and $\widetilde{d_1} \equiv d_1$.
Performing the matrix-vector multiplication in eq. \ref{eq:matrixeq}, we get
the following relations from the second-to-last and last row:
  \begin{equation}
    v_i = \frac{d_i - c_iv_{i+1}}{\widetilde{b_i}}, \quad
    v_n = \frac{\widetilde{d}_n}{\widetilde{b_n}}.
  \end{equation}
With these expressions, we can construct our general algorithm as follows:
  \begin{algorithm}[h!]
    \SetAlgoLined
    initialise $\vb{v}$, $\vb{a}$, $\vb{b}$, $\vb{c}$, $\vb{d}$\;
    \For{$i = 2, \dots, n$}{
      $b_i = b_i - \frac{a_{i-1}}{b_{i-1}}c_{i-1}$\;
      $d_i = d_i - \frac{a_{i-1}}{b_{i-1}}c_{i-1}$\;
    }
    $v_n = \frac{d_n}{b_n}$\;
    \For{$i = n-1, \dots, 1$}{
      $v_i = \frac{d_i - c_i v_{i+1}}{b_i}$\;
    }
  \end{algorithm}
  
This algorithm has a total of 8n FLOPS. 

If we now take into account that our matrix has only twos along the diagonal, and -1 above and below the diagonal, we can make a specialized algorithm. Plugging in theses values in the expression for $\widetilde{b_i}$ in equation \ref{eq:gaussian} gives us the following: 

	\begin{equation}
	\widetilde{b_i}=2-\frac{1}{\widetilde{b}_{i-1}}, \quad \widetilde{b}_1=2
	\end{equation}
We can prove by induction that this is the same as:

	\begin{equation}
	\widetilde{b}_i = \frac{i+1}{i}, \quad i \geq 1 
	\end{equation}

Since $\widetilde{b_i}$ is only a function of $i$ we can now set up $\mathbf{\widetilde{b}}$ in the initialisation. Plugging in the values in the remaining expressions gives:

	\begin{equation}
	\widetilde{d_i} = d_i + \frac{\widetilde{d}_{i-1}}{\widetilde{b}_{i-1}}, \quad
	v_i = \frac{\widetilde{d_i}+u_{i+1}}{\widetilde{b_i}}
	\end{equation}
where $v_n = \frac{\widetilde{d_n}}{\widetilde{b_n}}$. This gives us the following specialised algorithm, with a total of 4n FLOPS (not counting the initialisation of $\mathbf{\widetilde{b}}$):
	
	\begin{algorithm}[h!]
	\SetAlgoLined
	initialise $\vb{v}$, $\vb{b}$, $\vb{d}$\;
	\For{$i = 2, \dots, n$}{
		$d_i = d_i + \frac{d_{i-1}}{b_{i-1}}$\;

	}
	$v_n = \frac{d_n}{b_n}$\;
	\For{$i = n-1, \dots, 1$}{
		$v_i = \frac{d_i + v_{i+1}}{b_i}$\;
	}
	\end{algorithm}



\subsection{LU-decomposition}
\label{sec:LU}

\subsection{Error}
\label{sec:error}

We define the error for each mesh point as:

	\begin{equation}
	\epsilon_i=log_{10}\left(\left|\frac{v_i-u_i}{u_i}\right|\right)
	\end{equation}
where $u_i=u(x_i)$ is the analytical solution given by $u(x) = 1-(1-e^{-10})x-e^{-10x}$. 
